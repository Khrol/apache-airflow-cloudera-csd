{
  "name" : "AIRFLOW",
  "label" : "Airflow",
  "description" : "Airflow is a platform to programmatically author, schedule and monitor workflows.",
  "version" : "1.0.1",
  "runAs" : { 
    "user" : "root",
    "group" : "root"
  },
  "parcel" : {
    "requiredTags" : [ "airflow", "rabbitmq" ],
    "optionalTags" : []
  },
  "parameters" : [
    {
      "name": "dbType",
      "label": "Database Type",
      "description": "Type of the database for the Airflow to use",
      "type": "string_enum",
      "default": "mysql",
      "configurableInWizard": true,
      "validValues" : [ "postgresql", "mysql"],
      "required" : "true"
    },
    {
      "name": "dbHost",
      "label": "Database Host",
      "description": "Ip Address of the host where the Database has to be installed or already installed",
      "type": "string",
      "default": "localhost",
      "configurableInWizard": true,
      "required" : "true"
    },
    {
      "name": "dbUser",
      "label": "Database Username",
      "description": "Username of the database",
      "type": "string",
      "default": "root",
      "configurableInWizard": true,
      "required" : "true"
    },
    {
      "name": "dbPass",
      "label": "Database Password",
      "description": "Password of the above username to access the database",
      "type": "password",
      "default": "cloudera",
      "configurableInWizard": true,
      "required" : "true"
    },
    {
      "name" : "RabbitMQ.ipaddress",
      "label" : "RabbitMQ Ip address",
      "description" : "Ip address of the RabbitMQ node",
      "type" : "string",
      "default" : "localhost"
    },
    {
      "name" : "security",
      "label" : "Security (Optional)",
      "description" : "What security module to use (for example kerberos)",
      "type" : "string",
      "default" : ""
    },
    {
      "name" : "keytab",
      "label" : "Keytab (Optional)",
      "description" : "Location of keytab file",
      "type" : "string",
      "default" : ""
    },
    {
      "name" : "reinit_frequency",
      "label" : "Reinit Frequency (Optional)",
      "description" : "Frequency of tickets",
      "type" : "string",
      "default" : ""
    },
    {
      "name" : "principal",
      "label" : "Principal (Optional)",
      "description" : "Kerberos Principal",
      "type" : "string",
      "default" : ""
    },
    {
      "name" : "expose_config",
      "label" : "Expose Config (Optional)",
      "description" : "Expose the configuration file in the web server",
      "type" : "boolean",
      "default" : "false",
      "configurableInWizard": true
    },
    {
      "name" : "load_examples",
      "label" : "Load Examples (Optional)",
      "description" : "Whether to load the examples that ship with Airflow. It's good to get started, but you probably want to set this to False in a production environment",
      "type" : "boolean",
      "default" : "true",
      "configurableInWizard": true
    },
    {
      "name" : "airflow_home",
      "label" : "Airflow Home",
      "description" : "The home folder for airflow, default is ~/airflow.",
      "configName" : "airflow.home",
      "required" : "true",
      "type" : "string",
      "default" : "/var/lib/airflow",
      "configurableInWizard": true
    },
    {
      "name" : "dags_folder",
      "label" : "Dags Folder",
      "description" : "The folder where your airflow pipelines live, most likely a subfolder in a code repository",
      "configName" : "dags.folder",
      "required" : "true",
      "type" : "string",
      "default" : "/var/lib/airflow/dags"
    },
    {
      "name" : "base_log_folder",
      "label" : "Base Log Folder",
      "description" : "The folder where airflow should store its log files.",
      "configName" : "base.log.folder",
      "required" : "true",
      "type" : "string",
      "default" : "/var/log/airflow"
    },
    {
      "name" : "remote_base_log_folder",
      "label" : "Remote Base Log Folder",
      "description" : "Airflow can store logs remotely in AWS S3 or Google Cloud Storage. Users must supply a remote location RL (starting with either 's3://...' or 'gs://...') and an Airflow connection id that provides access to the storage location.",
      "configName" : "remote.base.log.folder",
      "required" : "false",
      "type" : "string",
      "default" : ""
    },
    {
      "name" : "remote_log_conn_id",
      "label" : "Remote Log Conn Id",
      "description" : "Airflow can store logs remotely in AWS S3 or Google Cloud Storage. Users must supply a remote location RL (starting with either 's3://...' or 'gs://...') and an Airflow connection id that provides access to the storage location.",
      "configName" : "remote.log.conn.id",
      "required" : "false",
      "type" : "string",
      "default" : ""
    },
    {
      "name" : "encrypt_s3_logs",
      "label" : "Encrypt S3 Logs",
      "description" : "Use server-side encryption for logs stored in S3.",
      "configName" : "encrypt.s3.logs",
      "required" : "false",
      "type" : "boolean",
      "default" : "false"
    },
    {
      "name" : "executor",
      "label" : "Executor",
      "description" : "The executor class that airflow should use. Choices include SequentialExecutor, LocalExecutor, CeleryExecutor",
      "configName" : "executor",
      "required" : "true",
      "type" : "string",
      "default" : "CeleryExecutor"
    },
    {
      "name" : "sql_alchemy_pool_size",
      "label" : "SQL Alchemy Pool Size",
      "description" : "The SqlAlchemy pool size is the maximum number of database connections in the pool.",
      "configName" : "sql.alchemy.pool.size",
      "required" : "true",
      "type" : "string",
      "default" : "5"
    },
    {
      "name" : "sql_alchemy_pool_recycle",
      "label" : "SQL Alchemy Pool Recycle",
      "description" : "The SqlAlchemy pool recycle is the number of seconds a connection can be idle in the pool before it is invalidated. This config does not apply to sqlite.",
      "configName" : "sql.alchemy.pool.recycle",
      "required" : "true",
      "type" : "string",
      "default" : "3600"
    },
    {
      "name" : "parallelism",
      "label" : "parallelism",
      "description" : "The amount of parallelism as a setting to the executor. This defines the max number of task instances that should run simultaneously on this airflow installation.",
      "configName" : "parallelism",
      "required" : "true",
      "type" : "string",
      "default" : "32"
    },
    {
      "name" : "dag_concurrency",
      "label" : "Dag Concurrency",
      "description" : "The number of task instances allowed to run concurrently by the scheduler",
      "configName" : "dag.concurrency",
      "required" : "true",
      "type" : "string",
      "default" : "16"
    },
    {
      "name" : "dags_are_paused_at_creation",
      "label" : "Dags Are Paused At Creation",
      "description" : "Are DAGs paused by default at creation",
      "configName" : "dags.are.paused.at.creation",
      "required" : "true",
      "type" : "boolean",
      "default" : "true",
      "configurableInWizard": true
    },
    {
      "name" : "non_pooled_task_slot_count",
      "label" : "Non Pooled Task Slot Count",
      "description" : "When not using pools, tasks are run in the 'default pool', whose size is guided by this config element",
      "configName" : "non.pooled.task.slot.count",
      "required" : "true",
      "type" : "string",
      "default" : "128"
    },
    {
      "name" : "max_active_runs_per_dag",
      "label" : "Max Active Runs Per Dag",
      "description" : "The maximum number of active DAG runs per DAG",
      "configName" : "max.active.runs.per.dag",
      "required" : "true",
      "type" : "string",
      "default" : "16"
    },
    {
      "name" : "default_owner",
      "label" : "Default Owner",
      "description" : "The default owner assigned to each new operator, unless provided explicitly or passed via 'default_args'",
      "configName" : "default.owner",
      "required" : "true",
      "type" : "string",
      "default" : "airflow"
    },
    {
      "name" : "web_server_port",
      "label" : "Web Server Port",
      "description" : "The port on which to run the web server",
      "configName" : "web.server.port",
      "required" : "true",
      "type" : "port",
      "default" : 8080
    }
  ],
  "serviceInit" : {
    "preStartSteps" : [
      {
        "commandName" : "INSTALL_AIRFLOW_INITDB_SERVCMD"
      }
    ]
  },
  "gateway" : {
    "alternatives" : {
      "name" : "airflow",
      "priority" : 50,
      "linkRoot" : "/tmp/airflowParent/"
    },
    "scriptRunner" : {
      "program" : "scripts/update_cfg.sh",
      "environmentVariables" : {
        "dbType" : "${dbType}",
        "dbHost" : "${dbHost}",
        "dbUser" : "${dbUser}",
        "dbPass" : "${dbPass}",
        "RABBITMQ_HOST" : "${RabbitMQ.ipaddress}",
        "airflow_home" : "${airflow_home}",
        "AIRFLOW_HOME" : "${airflow_home}",
        "dags_folder" : "${dags_folder}",
        "base_log_folder" : "${base_log_folder}",
        "remote_base_log_folder" : "${remote_base_log_folder}",
        "remote_log_conn_id" : "${remote_log_conn_id}",
        "encrypt_s3_logs" : "${encrypt_s3_logs}",
        "executor" : "${executor}",
        "sql_alchemy_pool_size" : "${sql_alchemy_pool_size}",
        "sql_alchemy_pool_recycle" : "${sql_alchemy_pool_recycle}",
        "parallelism" : "${parallelism}",
        "dag_concurrency" : "${dag_concurrency}",
        "dags_are_paused_at_creation" : "${dags_are_paused_at_creation}",
        "non_pooled_task_slot_count" :  "${non_pooled_task_slot_count}",
        "max_active_runs_per_dag" : "${max_active_runs_per_dag}",
        "default_owner" : "${default_owner}",
        "web_server_port" : "${web_server_port}",
        "security" : "${security}",
        "keytab" : "${keytab}",
        "reinit_frequency" : "${reinit_frequency}",
        "principal" : "${principal}",
        "expose_config" : "${expose_config}",
        "load_examples" : "${load_examples}"
      }
    },
    "configWriter" : {
      "generators" : [
        {
          "filename" : "airflow/airflowTest.cfg",
          "configFormat" : "properties",
          "includedParams" : [
            "airflow_home",
            "dags_folder",
            "base_log_folder",
            "remote_base_log_folder",
            "remote_log_conn_id",
            "encrypt_s3_logs",
            "executor",
            "sql_alchemy_pool_size",
            "sql_alchemy_pool_recycle",
            "parallelism",
            "dag_concurrency",
            "dags_are_paused_at_creation",
            "non_pooled_task_slot_count",
            "max_active_runs_per_dag",
            "default_owner",
            "web_server_port"
          ]
        }
      ]
    }
  },
  "inExpressWizard" : true,
  "icon" : "images/airflow.png",
  "rolesWithExternalLinks" : ["AIRFLOW_WEBSERVER"],
  "commands": [
    {
      "name": "INSTALL_AIRFLOW_INITDB_SERVCMD",
      "label": "Initialize Airflow DB",
      "description": "Initializes the Airflow DB",
      "roleName": "AIRFLOW_SCHEDULER",
      "roleCommand": "airflow_initdb_scheduler_rolecmd",
      "runMode": "single"
    },
    {
      "name": "INSTALL_AIRFLOW_RESETDB_SERVCMD",
      "label": "Resets Airflow DB",
      "description": "Resets the Airflow DB",
      "roleName": "AIRFLOW_SCHEDULER",
      "roleCommand": "airflow_resetdb_scheduler_rolecmd",
      "runMode": "single"
    }
  ],
  "roles" : [
    {
      "name" : "AIRFLOW_WEBSERVER",
      "label" : "Webserver",
      "pluralLabel" : "Webservers",
      "startRunner" : {
         "program" : "scripts/start_airflow_webserver.sh"
      },
      "externalLink" : {
        "name" : "webserver_web_ui",
        "label" : "Airflow WebUI",
        "url" : "http://${host}:8080"
      },
      "topology" : { 
          "minInstances" : 1 
      },
      "logging" : {
         "dir" : "/var/log/airflow",
         "filename" : "airflow-master-${host}.log",
         "configName" : "log.dir",
         "modifiable" : true,
         "loggingType" : "log4j"
      },
      "stopRunner" : {
         "runner" : {
             "program" : "scripts/stop_airflow_webserver.sh"
        }
      }
    },
    {
      "name" : "AIRFLOW_SCHEDULER",
      "label" : "Scheduler",
      "pluralLabel" : "Schedulers",
      "startRunner" : {
         "program" : "scripts/start_airflow_scheduler.sh"
      },
      "commands" : [
        {
         "name" : "airflow_initdb_scheduler_rolecmd",
         "label" : "Intialize Airflow DB",
         "description" : "This command will initialize the Airflow Database",
         "expectedExitCodes" : [0],
         "requiredRoleState" : "stopped",
         "commandRunner" : {
           "program" : "scripts/airflow_initdb.sh"
         }
        },
        {
         "name" : "airflow_resetdb_scheduler_rolecmd",
         "label" : "Reset Airflow DB",
         "description" : "This command will reset the Airflow Database",
         "expectedExitCodes" : [0],
         "requiredRoleState" : "stopped",
         "commandRunner" : {
           "program" : "scripts/airflow_resetdb.sh"
           }
         }
      ],
      "topology" : { 
          "maxInstances" : 1 
      }
    },
    {
      "name" : "AIRFLOW_WORKER",
      "label" : "Worker",
      "pluralLabel" : "Workers",
      "startRunner" : {
         "program" : "scripts/start_airflow_worker.sh"
      },
      "stopRunner" : {
         "runner" : {
             "program" : "scripts/stop_airflow_worker.sh"
        }
      }
    },
    {
      "name" : "RABBITMQ",
      "label" : "RabbitMQ",
      "pluralLabel" : "RabbitMQ",
      "startRunner" : {
         "program" : "scripts/start_rabbitmq.sh"
      },
      "stopRunner" : {
         "runner" : {
             "program" : "scripts/stop_rabbitmq.sh"
        }
      }
    },
    {
      "name" : "AIRFLOW_FLOWER",
      "label" : "Flower (Optional)",
      "pluralLabel" : "Flowers",
      "startRunner" : {
         "program" : "scripts/start_airflow_flower.sh"
      },
      "topology": {
        "minInstances" : "0"
      }
    },
    {
      "name" : "KERBEROS",
      "label" : "Kerberos",
      "pluralLabel" : "Kerberos",
      "startRunner" : {
        "program" : "scripts/start_kerberos.sh"
      },
      "topology" : {
        "minInstances" : "0"
      }
    }
  ]
}
